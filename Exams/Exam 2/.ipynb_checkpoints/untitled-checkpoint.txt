class Objective:
    
    def __init__(self, seed):
        
        self.seed = seed
        
    def __call__(self, trial):
        
        params = dict(n_estimators = trial.suggest_int('n_estimators', 100, 2000),
                      max_depth = trial.suggest_int('max_depth', 2, 10),
                      min_child_weight = trial.suggest_int('min_child_weight', 2, 20),
                      learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1, log = True),
                      gamma = trial.suggest_float('gamma', 0.0, 10.0),
                      colsample_bytree = trial.suggest_float('colsample_bytree', 0.2, 0.9),
                      subsample = trial.suggest_float('subsample', 0.2, 0.9))
        
        scores2 = list()
        
        skf = KFold(n_splits = 3, shuffle = True, random_state = self.seed)
        
        for train_idx, valid_idx in skf.split(X_train, Y_train):
            
            X_train2, X_valid2 = X_train.iloc[train_idx], X_train.iloc[valid_idx]
            Y_train2, Y_valid2 = Y_train.iloc[train_idx], Y_train.iloc[valid_idx]
            
            XGB_md = XGBRegressor(**params).fit(X_train1,Y_train1)
            
            pred_valid2 = XGB_md.predict(x_valid1)
            
            scores2.append(mean_squared_error(Y_valid1, pred_valid2, squared = False))   
            
        return np.mean(scores2)

study_2 = optuna.create_study(direction = 'minimize')
study_2.optimize(Objective(SEED), n_trials = N_TRIALS)